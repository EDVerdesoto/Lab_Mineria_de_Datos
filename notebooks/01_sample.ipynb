{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e431e41",
   "metadata": {},
   "source": [
    "## Descripción del Dataset y Metodología de Extracción\n",
    "\n",
    "### 1. El Dataset Utilizado\n",
    "\n",
    "El dataset seleccionado para este estudio es **CVEfixes (Versión 1.0.8)**. Este conjunto de datos constituye una colección automatizada y curada de vulnerabilidades y sus correspondientes correcciones extraídas de proyectos de software de código abierto.\n",
    "\n",
    "La información base se obtiene de los registros CVE (Common Vulnerabilities and Exposures) de la Base de Datos Nacional de Vulnerabilidades (NVD), vinculando estos registros con los repositorios de código fuente (GitHub, GitLab, Bitbucket) para extraer el código antes y después del parche de seguridad. El dataset está estructurado como una base de datos relacional que permite el análisis a nivel de commit, archivo y método. Para este trabajo, se seleccionó el nivel de abstracción de **método (función)**.\n",
    "\n",
    "### 2. Consultas y Procesamiento de Datos\n",
    "\n",
    "Para la construcción del dataset final orientado al entrenamiento de modelos de Machine Learning, se ejecutó un proceso de extracción y limpieza dividido en dos etapas: extracción SQL y post-procesamiento en Python.\n",
    "\n",
    "#### A. Extracción SQL\n",
    "\n",
    "Se utilizó la siguiente consulta SQL sobre la base de datos SQLite para unificar la información dispersa en las tablas `method_change`, `file_change`, `fixes` y `cwe_classification`. Esta consulta selecciona las métricas de código, el código fuente y genera la etiqueta de clasificación (target), asegurando la eliminación de registros duplicados exactos desde la fuente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccc641",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT DISTINCT\n",
    "    m.code,\n",
    "    m.parameters,\n",
    "    f.programming_language,\n",
    "    m.nloc,\n",
    "    m.complexity,\n",
    "    m.token_count,\n",
    "    m.top_nesting_level,\n",
    "    CASE \n",
    "        WHEN m.before_change = 'False' THEN 'Safe'\n",
    "        ELSE cc.cwe_id \n",
    "    END AS cwe_id\n",
    "FROM method_change m\n",
    "JOIN file_change f ON m.file_change_id = f.file_change_id\n",
    "JOIN fixes fx ON f.hash = fx.hash\n",
    "LEFT JOIN cwe_classification cc ON fx.cve_id = cc.cve_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595b9d1",
   "metadata": {},
   "source": [
    "#### B. Limpieza de Datos (Post-Procesamiento)\n",
    "\n",
    "Posterior a la extracción, se aplicó un script de limpieza en Python para mitigar el ruido en las etiquetas (\"Label Noise\"). Este paso es crítico debido a la naturaleza de los commits de corrección, donde un cambio puede no afectar a todas las funciones extraídas, generando ambigüedad.\n",
    "\n",
    "Las acciones de limpieza fueron:\n",
    "\n",
    "1. **Eliminación de duplicados exactos:** Se utilizó `drop_duplicates` para remover filas idénticas remanentes.\n",
    "\n",
    "2. **Eliminación de inconsistencias (Falsos Cambios):** Se identificaron y eliminaron los fragmentos de código que presentaban etiquetas contradictorias (el mismo código marcado simultáneamente como 'Safe' y con un 'CWE-ID'). Esto asegura que el modelo no reciba entradas idénticas con salidas diferentes.\n",
    "\n",
    "### 3. Características del Dataset Resultante\n",
    "\n",
    "El dataset final (`dataset_ml_ready.csv`) cuenta con las siguientes características:\n",
    "\n",
    "* **code:** Código fuente de la función.\n",
    "* **parameters:** Parámetros de la función para contexto de entrada.\n",
    "* **programming_language:** Lenguaje de programación (ej. C, PHP, Java).\n",
    "* **nloc:** Número de líneas de código.\n",
    "* **complexity:** Complejidad ciclomática.\n",
    "* **token_count:** Número total de tokens.\n",
    "* **top_nesting_level:** Nivel máximo de anidamiento.\n",
    "* **cwe_id (Target):** Etiqueta de clasificación ('Safe' o el identificador del CWE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aac60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuracion de archivos\n",
    "INPUT_FILE = 'dataset_con_params.csv'\n",
    "OUTPUT_FILE = 'dataset_ml_ready.csv'\n",
    "\n",
    "print(f\"Cargando {INPUT_FILE}...\")\n",
    "# Cargamos el CSV generado por SQLite\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "print(f\"Filas originales: {len(df)}\")\n",
    "\n",
    "# Si una fila es IDENTICA a otra, se elimina.\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Filas tras eliminar duplicados exactos: {len(df)}\")\n",
    "\n",
    "print(\"Buscando codigos con etiquetas contradictorias\")\n",
    "conteo_etiquetas = df.groupby('code')['cwe_id'].nunique()\n",
    "codigos_ambiguos = conteo_etiquetas[conteo_etiquetas > 1].index\n",
    "\n",
    "num_ambiguos = len(codigos_ambiguos)\n",
    "print(f\"Se encontraron {num_ambiguos} fragmentos de codigo con etiquetas contradictorias.\")\n",
    "\n",
    "if num_ambiguos > 0:\n",
    "    print(\"Eliminando conflictos...\")\n",
    "    # Filtramos: Nos quedamos solo con los codigos que NO esten en la lista de ambiguos\n",
    "    df_limpio = df[~df['code'].isin(codigos_ambiguos)]\n",
    "else:\n",
    "    df_limpio = df\n",
    "\n",
    "print(f\"Filas finales limpias: {len(df_limpio)}\")\n",
    "print(f\"Guardando en {OUTPUT_FILE}...\")\n",
    "df_limpio.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"Proceso finalizado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
