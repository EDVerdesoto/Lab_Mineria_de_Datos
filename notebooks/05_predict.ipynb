{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c5bfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.v3.map_cwe import LABEL_NAMES, NUM_LABELS\n",
    "from src.v3.model import VulnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "120b7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "STRIDE = 256\n",
    "DEVICE = 'cpu'\n",
    "MODEL_NAME = \"microsoft/codebert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fe75a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas del archivo de código para probar y del modelo entrenado\n",
    "OUTPUT_DIR = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25e63d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division del arhcivo código en funciones [code: string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b70b747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convirtiendo best_model.bin a formato save_pretrained...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../../tokenizer_config.json',\n",
       " '../../special_tokens_map.json',\n",
       " '../../vocab.json',\n",
       " '../../merges.txt',\n",
       " '../../added_tokens.json',\n",
       " '../../tokenizer.json')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda NUEVA al final (ejecutar UNA VEZ para convertir):\n",
    "print(\"Convirtiendo best_model.bin a formato save_pretrained...\")\n",
    "\n",
    "# Cargar modelo base\n",
    "model_convert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "# Cargar pesos entrenados\n",
    "model_convert.load_state_dict(\n",
    "    torch.load(f\"{OUTPUT_DIR}/best_model.bin\", map_location='cpu')\n",
    ")\n",
    "\n",
    "# Guardar completo\n",
    "model_convert.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# También el tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4fd1c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(code: str) -> List[Dict]:\n",
    "    tokens = tokenizer.encode(code, add_special_tokens=False, truncation=False)\n",
    "    eff_len = MAX_LEN - 2\n",
    "    \n",
    "    if len(tokens) <= eff_len:\n",
    "        enc = tokenizer.encode_plus(code, max_length=MAX_LEN,\n",
    "                                            padding='max_length', truncation=True, return_tensors='pt')\n",
    "        return [{'input_ids': enc['input_ids'].flatten(), \n",
    "                    'attention_mask': enc['attention_mask'].flatten()}]\n",
    "    \n",
    "    windows = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + eff_len, len(tokens))\n",
    "        ids = [tokenizer.cls_token_id] + tokens[start:end] + [tokenizer.sep_token_id]\n",
    "        pad = MAX_LEN - len(ids)\n",
    "        windows.append({\n",
    "            'input_ids': torch.tensor(ids + [tokenizer.pad_token_id] * pad),\n",
    "            'attention_mask': torch.tensor([1] * len(ids) + [0] * pad)\n",
    "        })\n",
    "        start += STRIDE\n",
    "        if len(tokens) - start < eff_len // 4:\n",
    "            break\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f0fdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(codes: List[str]) -> List[Dict]:\n",
    "    all_ids, all_masks = [], []\n",
    "    \n",
    "    for code in codes:\n",
    "        # Tokenizar cada código (sin sliding window manual)\n",
    "        enc = tokenizer.encode_plus(\n",
    "            code,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        all_ids.append(enc['input_ids'].squeeze(0))\n",
    "        all_masks.append(enc['attention_mask'].squeeze(0))\n",
    "    \n",
    "    input_ids = torch.stack(all_ids).to(DEVICE)\n",
    "    attention_mask = torch.stack(all_masks).to(DEVICE)\n",
    "    \n",
    "    model_convert.eval()\n",
    "    with torch.no_grad():\n",
    "        # AutoModelForSequenceClassification retorna un objeto con .logits\n",
    "        outputs = model_convert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "    \n",
    "    results = []\n",
    "    for j in range(len(codes)):\n",
    "        pred_id = int(np.argmax(probs[j]))\n",
    "        results.append({\n",
    "            'label': LABEL_NAMES[pred_id],\n",
    "            'label_id': pred_id,\n",
    "            'confidence': float(probs[j, pred_id]),\n",
    "            'is_vulnerable': pred_id != 0,\n",
    "            'probabilities': {n: float(probs[j, k]) for k, n in enumerate(LABEL_NAMES)}\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "10394185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(code: str) -> Dict:\n",
    "        return predict_batch([code])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef06258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(code: str) -> Dict:\n",
    "    result = predict(code)\n",
    "    conf = result['confidence']\n",
    "    \n",
    "    recommendations = {\n",
    "        'Safe': \"Código seguro.\",\n",
    "        'CWE-79': \"Posible XSS. Sanitiza outputs.\",\n",
    "        'CWE-89': \"Posible SQL Injection. Usa queries parametrizadas.\",\n",
    "        'CWE-78': \"Posible Command Injection. Evita shell=True.\",\n",
    "        'CWE-22': \"Posible Path Traversal. Valida rutas.\",\n",
    "        'CWE-434': \"Posible File Upload inseguro. Valida archivos.\",\n",
    "        'CWE-352': \"Posible CSRF. Implementa tokens.\",\n",
    "        'Other': \"Revisar manualmente.\"\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'prediction': result['label'],\n",
    "        'confidence': conf,\n",
    "        'confidence_level': 'alta' if conf > 0.7 else 'media' if conf > 0.5 else 'baja',\n",
    "        'is_vulnerable': result['is_vulnerable'],\n",
    "        'risk': 'ALTO' if result['is_vulnerable'] and conf > 0.7 else 'MEDIO' if result['is_vulnerable'] else 'BAJO',\n",
    "        'recommendation': recommendations.get(result['label'], \"Revisar.\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d16a41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vuln_code = '''\n",
    "def get_user(user_id):\n",
    "    query = \"SELECT * FROM users WHERE id = \" + user_id\n",
    "    cursor.execute(query)\n",
    "'''\n",
    "safe_code = '''\n",
    "def get_user(user_id):\n",
    "    cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e8d232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis del código vulnerable:\n",
      "{'label': 'Safe', 'label_id': 0, 'confidence': 0.5147185921669006, 'is_vulnerable': False, 'probabilities': {'Safe': 0.5147185921669006, 'CWE-79': 0.012471646070480347, 'CWE-89': 0.0767425075173378, 'CWE-78': 0.0009228368871845305, 'CWE-22': 0.0010134786134585738, 'CWE-434': 0.00163276179227978, 'CWE-352': 0.0026988645549863577, 'Other': 0.3897992670536041}}\n",
      "Análisis del código seguro:\n",
      "{'label': 'Other', 'label_id': 7, 'confidence': 0.5140795111656189, 'is_vulnerable': True, 'probabilities': {'Safe': 0.4438059329986572, 'CWE-79': 0.012255201116204262, 'CWE-89': 0.025257835164666176, 'CWE-78': 0.0009352525230497122, 'CWE-22': 0.0007075853645801544, 'CWE-434': 0.001013824949041009, 'CWE-352': 0.0019448746461421251, 'Other': 0.5140795111656189}}\n"
     ]
    }
   ],
   "source": [
    "# Predecir la clase del código usando el modelo entrenado\n",
    "analysis = predict(vuln_code)\n",
    "print(\"Análisis del código vulnerable:\")\n",
    "print(analysis)\n",
    "analysis_s = predict(safe_code)\n",
    "print(\"Análisis del código seguro:\")\n",
    "print(analysis_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd680b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función con técnicas de IA explicable para detectar la línea de código vulnerable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82172f5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generar reporte para el usuario final usando la función xAI sobre las funciones predichas como vulnerables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
